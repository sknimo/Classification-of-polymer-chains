{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2655fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6d0574",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/interim/distribution.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#loading our file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m fname \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/interim/distribution.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m chains_distribution \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m chains_distribution\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/interim/distribution.xlsx'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#loading our file\n",
    "fname ='../data/interim/distribution.xlsx'\n",
    "chains_distribution = pd.read_csv(fname)\n",
    "chains_distribution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ba6db0",
   "metadata": {},
   "source": [
    "## Getting the initial guesses\n",
    "\n",
    "With the generated dataset we evaluate the initial guesses by performing clustering. The difference between the use of GMM in this step and the previous is that, in the previous step we fitted one gaussian to every data point in effect it meant that every datapoint belonged to its own cluster with an infinite likehood. In this step however, by providing a fewer number of clusters each data point would be assigned to one of the clusters based on probability. For example for 3 clusters and 100 datapoints, each datapoint would be assigned to one of the 3 clusters based on some calculated probability.\n",
    "\n",
    "Let us write a function for that. It would have as input parameters, the generated data and the number of clusters to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6afb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmmClustering(generateddata,nComponents):\n",
    "    \"\"\"Performs clustering on given distribution\n",
    "    Args:\n",
    "        generatedData(df): columns =[LogM,dwdlogM]\n",
    "        nComponents(int): the number of clusters to identify\n",
    "    returns: \n",
    "        list: [weight, mean,standard deviation] of each cluster \n",
    "    \"\"\"\n",
    "    # creating a model and fitting the model to the data\n",
    "    gmm =GaussianMixture(n_components=nComponents, covariance_type='full').fit(generateddata) \n",
    "    mean = gmm.means_[:,0] # the first columns contains the means   \n",
    "    #covariance returns a set of arrays each for one cluster. The main diagonal contains the variance\n",
    "    covariance = gmm.covariances_    \n",
    "    # the weights here are the population fractions\n",
    "    weight = gmm.weights_\n",
    "    \n",
    "    cluster_parms =[] # to store the cluster parameters\n",
    "    for i in range(nComponents):\n",
    "        cluster_parms.append([weight[i],mean[i],np.sqrt(np.diag(covariance[i]))[0]])\n",
    "    return list(np.hstack(cluster_parms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e3c09f",
   "metadata": {},
   "source": [
    "The function above (gmmClustering) would return the estimated mean location of each cluster, the weight fractions and standard deviations. To observe the output we now write a function which would accept the evaluated clusters parameters and generate the gaussian curve.\n",
    "\n",
    "So we next write a function for the gaussian curves. This function would accept any number of parameters and will return the sum of the gaussians as a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c91f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the gaussian function\n",
    "def gaussian_func(x,*params):\n",
    "    \"\"\" generate the gaussian distribution\"\"\"\n",
    "    y = np.zeros_like(x)\n",
    "    for i in range(0,len(params),3):\n",
    "        amp= params[i] # amplitude\n",
    "        ctr = params[i+1] # peak location\n",
    "        wid = params[i+2] # standard deviation\n",
    "        y += amp*np.exp(-((x-ctr)/wid)**2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e49bd1",
   "metadata": {},
   "source": [
    "Armed with these 2 functions let us now test it on 2 clusters. That is to say, we assume that the distribution is made up of two subpopulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters = 2\n",
    "clusters_params2 = gmmClustering(generated_distribution,nComponents=number_of_clusters)\n",
    "print(clusters_params2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252b762",
   "metadata": {},
   "source": [
    "The outputs are the cluster's weight fractions, peak location and standard deviation respectively.\n",
    "With these initial guesses we can now reconstruct the distribution using the gaussian_func function and minimize the error between the reconstructed distribution generated and the original data.\n",
    "\n",
    "We would need an optimization routine for that and would use the curve_fit function from sklearn.optimize. Let's write the optimizeGmmParameter function to handle that. It would return the adjusted cluster parameters that would result in the minimal error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccf15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeGmmParameter(rawdata, gmm_parameters,gaussFunct):\n",
    "    \"\"\"Optimize parameters obtained from the gmm model\n",
    "    Args:\n",
    "        rawData(df): raw data\n",
    "        gmm_parameters[list]: list of init parameters obtained from gmm\n",
    "        gaussFunct(functions): gaussian functions to be used to perform curve optimization\n",
    "    returns:\n",
    "        array: [amp, peak location, width]\n",
    "    \"\"\"\n",
    "    x_raw = rawdata.iloc[:,0].dropna().values;y_raw=rawdata.iloc[:,1].dropna().values\n",
    "    \n",
    "    # returns the fitting parameters, accepts the function,data and init_para\n",
    "    popt_gauss, pcov_gauss = curve_fit(gaussFunct, x_raw, y_raw, p0=gmm_parameters, maxfev = 50000)\n",
    "    optimizedParameter = np.asarray(popt_gauss).reshape(-1,3)\n",
    "    return sorted(optimizedParameter, key= lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_parms2 = optimizeGmmParameter(digitized_data, clusters_params2,gaussian_func)\n",
    "print(optimized_parms2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dbf84b",
   "metadata": {},
   "source": [
    "Now observing the deconvoluted peaks (figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(digitized_data.iloc[:,0],digitized_data.iloc[:,1],'k', lw=3,alpha=0.3)\n",
    "for i in range(len(optimized_parms2)):\n",
    "    plt.plot(digitized_data.iloc[:,0],gaussian_func(digitized_data.iloc[:,0],*optimized_parms2[i]),lw=3)\n",
    "\n",
    "plt.xlabel('$Log \\; M$')\n",
    "plt.ylabel('$dw/dLogM$')\n",
    "plt.title('Figure 3')\n",
    "# plt.savefig('two_clusters.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79167c0b",
   "metadata": {},
   "source": [
    "The output shown in figure 3 is not perfect possibly indicating that there could be more than 2 clusters. Increasing the number of clusters to 3 produces the results in figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f35a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing clustering\n",
    "number_of_clusters = 3\n",
    "clusters_params3 = gmmClustering(generated_distribution,nComponents=number_of_clusters)\n",
    "# performing curve fitting\n",
    "optimized_parms3 = optimizeGmmParameter(digitized_data, clusters_params3,gaussian_func)\n",
    "# observing the output\n",
    "plt.plot(digitized_data.iloc[:,0],digitized_data.iloc[:,1],'k', lw=3,alpha=0.3)\n",
    "for i in range(len(optimized_parms3)):\n",
    "    plt.plot(digitized_data.iloc[:,0],gaussian_func(digitized_data.iloc[:,0],*optimized_parms3[i]),lw=3)\n",
    "\n",
    "plt.xlabel('$Log \\; M$')\n",
    "plt.ylabel('$dw/dLogM$')\n",
    "plt.title('Figure 4')\n",
    "# plt.savefig('three_clusters.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b056d3",
   "metadata": {},
   "source": [
    "At this point we can combine the first 2 peaks to yield figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10104a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = digitized_data.iloc[:,0]\n",
    "lower_portion = gaussian_func(x_values,*optimized_parms3[0])+ gaussian_func(digitized_data.iloc[:,0],*optimized_parms3[1])\n",
    "higher_portion = gaussian_func(x_values,*optimized_parms3[-1])\n",
    "\n",
    "plt.plot(x_values,lower_portion)\n",
    "plt.plot(x_values,higher_portion)\n",
    "plt.plot(x_values,digitized_data.iloc[:,1],'k', lw=3,alpha=0.3)\n",
    "plt.title('Figure 5')\n",
    "# plt.savefig('finalOutput.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db77fe",
   "metadata": {},
   "source": [
    "As shown, the deconvolution looks much better. \n",
    "Clustering was only used to help us get the initial guess, so we won't be making use of metrics such as BIC or AIC to evaluate the best number of clusters that fits well, so we would instead make use of a for loop and iterate over a possible number of clusters and optimize the output. All put together as a function is presented below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_deconvolution(originalData,generatedData,n_clusters,gaussian_func):\n",
    "    n_components =np.arange(2,n_clusters)\n",
    "    par_list = []\n",
    "    for n in n_clusters:\n",
    "\n",
    "        init_guess = gmmClustering(generatedData,n)\n",
    "        opt_param = optimizeGmmParameter(originalData, init_guess,gaussian_func)\n",
    "        par_list.append(opt_param)\n",
    "        plt.plot(df.iloc[:,0],df.iloc[:,1],'k', alpha=0.3,label='orig')\n",
    "\n",
    "        for i in range(len(opt_param)):\n",
    "            a = gausfunc(df.iloc[:,0],*opt_param[i])\n",
    "            plt.plot(df.iloc[:,0],a)\n",
    "        plt.xlabel('$Log \\; M$')\n",
    "        plt.ylabel('$dw/dLogM$')\n",
    "        plt.show()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce35cb1a",
   "metadata": {},
   "source": [
    "In this article, it was shown that peak deconvolution can be greatly improve with the use of clustering. Thanks for your attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da33295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
